(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{297:function(e,t,a){"use strict";a.r(t);var s=a(13),n=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"▶️-umx-js-web-demo"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#▶️-umx-js-web-demo"}},[e._v("#")]),e._v(" ▶️ umx.js - web demo")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://webaudioconf2021.com/wp-content/uploads/2021/06/stoeter_wac.pdf",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://img.shields.io/badge/web%20audio%20conference%20paper-pdf-orange.svg",alt:"Web Audio Paper (PDF)"}}),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://github.com/sigsep/open-unmix-js/",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://img.shields.io/badge/github-repository-blue.svg",alt:"Repository"}}),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("In this demo, we showcase an audio separation models that performs separation in the browser. The  model is derived from the full open-unmix. The models were converted to tensorflow via ONNX and on-the-wire weight quantization was applied to reduce the models file size. We manually converted the python-based pre-and post-processing pipelines from Python to JavaScript. Thus, as part of the release of this demo, we make a fully invertible tensorflow.js pipeline available.")]),e._v(" "),t("div",{staticClass:"custom-block warning"},[t("p",{staticClass:"custom-block-title"},[e._v("Note")]),e._v(" "),t("p",[e._v("Note, that the model is very slow and we do not advice to separate tracks longer than 30 seconds.")])]),e._v(" "),t("iframe",{attrs:{src:"https://sigsep.github.io/open-unmix-js/",width:"100%",height:"680",frameborder:"0"}}),e._v(" "),t("h2",{attrs:{id:"cite"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cite"}},[e._v("#")]),e._v(" Cite")]),e._v(" "),t("div",{staticClass:"language-latex extra-class"},[t("pre",{pre:!0,attrs:{class:"language-latex"}},[t("code",[e._v("@proceedings"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("stoteropen,\n  title="),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("open.unmix.app-towards audio separation on the edge"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v(',\n  conference="2021 Web Audio Conference",\n  author='),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n      St"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),t("span",{pre:!0,attrs:{class:"token function selector"}},[e._v('\\"')]),e._v("o"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("ter, Fabian-Robert and Machry, Maria Clara and de Andrade Vaz, Delton and Uhlich, Stefan and Mitsufuji, Yuki and Liutkus, Antoine"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);